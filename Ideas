Problems:
- Die Bewertung erfolgt erst nach Abschluss des gesamten Trainingsvorgangs, was enorm zeitaufwendig ist
- Der Trainingsfortschritt bleibt nicht von Generation zu Generation erhalten, in jeder Generation werden die Netze neu zufällig initialisiert
- Neue Netze werden oft schon nach einer Iteration wieder verworfen, da sie nicht die Zeit haben entwickelt zu werden
  und bei der Bewertung dementsprechend schlecht abschneiden

Enhancements:
- Training zunächst nur auf kleinen Ausschnitten des
Trainingsdatensatzes, Abtrennung eines Validierungsdatensatzes und
Nutzung von Early-Stopping-Verfahren
- Trainingsfortschritt dort wo möglich zwischen Generationen erhalten
(z.B. Parameter Layer-weise zwischenspeichern, neu initialisieren nur
selten und natürlich bei neu hinzugefügten Layern)
- Besseres Auswahlverfahren für überlebende / zu mutierende Netze
(ähnlich wie NEAT), dabei neue bzw. weniger trainierte Netze schützen
(Trainingsfortschritt in Ähnlichkeitsfunktion einbauen)
- Möglicherweise den Suchraum um neue Neuronale-Netz-Architekturen erweitern

Genome:
- Nodes: Filter/Pooling Layer:
  - Filter:
    * 3D: Tiefe + Höhe/Breite
    * Wenn Höhe Filter zu klein:
      1. Nimm die ersten Layer von Depth
      2. Wiederhole bis passt
    * Wenn Höhe Filter zu groß:
      1. Cut the rest of data
      2. Start again an.
  -> Dont use all the data vs smaller thing. (maybe var)
- Edges: -

Ideas:
- Train a bit everywhere. Top Species get extra compute time. Top Individuals of Species get more of that.
  More training -> higher penalty
- Every gene has a detail to its weight. e+v of all weights, e+v in regions (e.g. col,row,blocks), all weights
  Higher detail -> higher penalty
- Mutation chances change dynamically (What works?)
(-) dilation, bias
(-) Mutation exception/variance
    Same for the selection of what genes to mutate
- Bessere Visualisierung, Layerweise gerade verbinden
- pool stride dial
- better structure seperate algorithm / initialization/ data


Genes:
- Conv
- Pool
- Dense